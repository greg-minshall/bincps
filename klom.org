* [[https://twitter.com/kltblom][Kristian Blom]]: does recent (20 years?) change in US income distribution matter?
** investigating

Kristian Blom [[https://twitter.com/kltblom/status/932394678241988609][showed a PDF]] (1971-2015), from Financial Times (based on
data from Pew Trust).  i don't see where to get that data.  but,
[[https://www2.census.gov/programs-surveys/cps/tables/time-series/historical-income-households/h01ar.xls][Census Bureau]] has something that breaks down by each fifth and top 5%.

#+BEGIN_SRC R :session ss :var tseries=tseries
colnames(tseries) <- c("year", "number", "lowest", "second", "third", "fourth", "llimittop5")
#+END_SRC

#+RESULTS:
| year       |
| number     |
| lowest     |
| second     |
| third      |
| fourth     |
| llimittop5 |

he has about 50 buckets.  i have 6.  sigh.

#+name: tseries
#+BEGIN_SRC sh
  xls2csv census/h01ar.xls |
      awk '/2016 Dollars/ { ok = 1; next} \
          /^"[12]/ {
                   if (ok) { 
                      gsub(/ *\([0-9][0-9]\) */, ""); 
                      gsub(/"/, ""); 
                      print;
                    }}' 2>&1 |
      tac
#+END_SRC

#+RESULTS: tseries
| 1967 |  60813 | 18856 | 36768 | 52186 |  74417 | 119419 |
| 1968 |  62214 | 20098 | 38103 | 54614 |  76737 | 120053 |
| 1969 |  63401 | 20699 | 39718 | 57441 |  80478 | 126218 |
| 1970 |  64778 | 20350 | 38985 | 56703 |  80899 | 127880 |
| 1971 |  66676 | 20088 | 38294 | 56353 |  80353 | 127602 |
| 1972 |  68251 | 20786 | 40033 | 59167 |  84686 | 136292 |
| 1973 |  69859 | 21238 | 40839 | 60425 |  87000 | 139832 |
| 1974 |  71163 | 21340 | 39585 | 58493 |  84892 | 134366 |
| 1975 |  72867 | 20288 | 38076 | 57536 |  82611 | 130365 |
| 1976 |  74142 | 20738 | 38636 | 58856 |  84678 | 134287 |
| 1977 |  76030 | 20694 | 38977 | 59411 |  86616 | 137142 |
| 1978 |  77330 | 21338 | 40346 | 61046 |  88785 | 142036 |
| 1979 |  80776 | 21594 | 40103 | 61700 |  89461 | 144557 |
| 1980 |  82368 | 20745 | 38905 | 59645 |  87332 | 140543 |
| 1981 |  83527 | 20340 | 38023 | 58809 |  86946 | 139925 |
| 1982 |  83918 | 20080 | 38191 | 58352 |  87015 | 143636 |
| 1983 |  85290 | 20516 | 38149 | 58550 |  88485 | 145579 |
| 1984 |  86789 | 20909 | 39134 | 60292 |  91077 | 150768 |
| 1985 |  88458 | 21154 | 39801 | 61657 |  92731 | 153220 |
| 1986 |  89479 | 21430 | 40990 | 63616 |  96164 | 161255 |
| 1987 |  91124 | 21835 | 41447 | 64697 |  97780 | 163619 |
| 1988 |  92830 | 22210 | 41953 | 65380 |  98722 | 167109 |
| 1989 |  93347 | 22614 | 43000 | 66089 | 100414 | 171533 |
| 1990 |  94312 | 22271 | 42159 | 64498 |  98359 | 168813 |
| 1991 |  95669 | 21646 | 41260 | 63729 |  97578 | 165727 |
| 1992 |  96426 | 21136 | 40494 | 63575 |  97304 | 166101 |
| 1993 |  97107 | 21217 | 40380 | 63473 |  98663 | 171210 |
| 1994 |  98990 | 21518 | 40389 | 64269 | 100717 | 176013 |
| 1995 |  99627 | 22536 | 42121 | 65734 | 101921 | 176848 |
| 1996 | 101018 | 22513 | 42318 | 67084 | 103684 | 182230 |
| 1997 | 102528 | 22979 | 43571 | 68640 | 106690 | 188834 |
| 1998 | 103874 | 23727 | 44768 | 71163 | 110418 | 194628 |
| 1999 | 106434 | 24702 | 46014 | 72630 | 114216 | 204698 |
| 2000 | 108209 | 24985 | 46009 | 72742 | 114000 | 202470 |
| 2001 | 109297 | 24361 | 45162 | 71849 | 113195 | 204021 |
| 2002 | 111278 | 23911 | 44545 | 70950 | 112127 | 200192 |
| 2003 | 112000 | 23468 | 44369 | 71059 | 113358 | 201120 |
| 2004 | 113343 | 23489 | 44059 | 70177 | 111818 | 199682 |
| 2005 | 114384 | 23570 | 44244 | 70864 | 112705 | 204014 |
| 2006 | 116011 | 23850 | 44967 | 71425 | 115508 | 207146 |
| 2007 | 116783 | 23489 | 45262 | 71770 | 115758 | 204892 |
| 2008 | 117181 | 23089 | 43476 | 69924 | 111744 | 200658 |
| 2009 | 117538 | 22880 | 43124 | 69134 | 111865 | 201359 |
| 2010 | 119927 | 22017 | 41832 | 67702 | 110116 | 198686 |
| 2011 | 121084 | 21617 | 41096 | 66609 | 108375 | 198438 |
| 2012 | 122459 | 21533 | 41568 | 67511 | 108818 | 199827 |
| 2013 | 122952 | 21535 | 41408 | 67492 | 109129 | 201957 |
| 2013 | 123931 | 21638 | 42282 | 69242 | 113582 | 211362 |
| 2014 | 124587 | 21728 | 41754 | 69153 | 113811 | 209419 |
| 2015 | 125819 | 23088 | 44061 | 72911 | 118480 | 217172 |
| 2016 | 126224 | 24002 | 45600 | 74869 | 121018 | 225251 |

a [[https://fas.org/sgp/crs/misc/RS20811.pdf][report]] from the Congressional Research Service gives nice numbers
for 2012.  this probably comes from (the 2012-version of) [[https://www.census.gov/data/tables/time-series/demo/income-poverty/cps-hinc/hinc-06.html][hinc-06]],
from the Census Bureau.  sadly, hinc-06.xls seems to go back only a
few years.

hinc-06.xls: 2017 2016 2015 2014 2013
hinc-06_000.xls: 2012
new06_000.txt: 2003

([[https://www.census.gov/popclock/][US, world population clock]])

[[https://usa.ipums.org/usa/][ipums.org]] is some sort of data service.  (it uses [[http://www.nber.org/data/current-population-survey-data.html][NBER data]].)  the
ipums data is unaggregated.  about 2MB for a file (1995).  and, of
course, many variables i don't understand.  plus, in nominal dollars.
but, the fact that it is unaggregated means that one can put in real
dollars *before* binning.  (though, when looking at a CDF, one can
convert each year's bin's into real dollars after the fact without
affecting things.)

[[http://www.pressure.to/works/hbai_in_r/][households below average income]] analysis in R.  for UK data, however.

[[https://www.kdnuggets.com/2014/06/data-visualization-census-data-with-r.html][data-visualization-census-data-with-r]].  old, broken links, etc.

[[https://www.r-bloggers.com/how-to-make-maps-with-census-data-in-r/][how-to-make-maps-with-census-data-in-r]] is newer.

[[http://users.stat.umn.edu/~almquist/software.html][Zach Almquist]] has 10-year census data;  [[https://www.jstatsoft.org/article/view/v037i06][paper]].

[[https://www.bls.gov/cps/][BLS]] CPS page.  however, "All self-employed persons are excluded,
regardless of whether their businesses are incorporated."

the [[https://statisticalatlas.com/United-States/Household-Income][Statistical Atlas]] has nice graphics (though maybe not time
series).  from American Community (?) Survey.

[[https://www.cbpp.org/research/poverty-and-inequality/a-guide-to-statistics-on-historical-trends-in-income-inequality][a-guide-to-statistics-on-historical-trends-in-income-inequality]].

the [[https://www.cbo.gov/publication/51361][CBO]] has data, but mostly quintile-level.

[[https://cps.ipums.org/cps-action/downloads/extract_files/cps_00002.xml][IPUMS columns]]:
- YEAR
- [[https://cps.ipums.org/cps-action/variables/SERIAL][SERIAL]]: household serial number
- [[https://cps.ipums.org/cps-action/variables/HWTSUPP#codes_section][HWTSUPP]]: household weight, Supplement
- [[https://cps.ipums.org/cps-action/variables/CPSID#codes_section][CPSID]]: CPS household record
- [[https://cps.ipums.org/cps-action/variables/ASECFLAG][ASECFLAG]]: flag for ASEC
- [[https://cps.ipums.org/cps-action/variables/HHINCOME][HHINCOME]]: total household income
- [[https://cps.ipums.org/cps-action/variables/MONTH][MONTH]]: the calendar month of the CPS interview
- [[https://cps.ipums.org/cps-action/variables/PERNUM][PERNUM]]: person number in sample unit
- [[https://cps.ipums.org/cps-action/variables/CPSIDP][CPSIDP]]: CPSID, person record
- [[https://cps.ipums.org/cps-action/variables/WTSUPP#description_section][WTSUPP]]: supplement weight

to format one file:
#+BEGIN_SRC sh :results output
  ((zcat ipums/cps_00001.csv.gz | head -1 | sed 'sx"xxg' | sed s'x,x xg');
   (zcat ipums/cps_00001.csv.gz | tail -n+1 | sed s'x,x xg' | sort -n -k6)) |
      column -t
#+END_SRC

#+RESULTS:


#+BEGIN_SRC awk :shebang "#!/usr/bin/awk -f" :tangle realize
  BEGIN {
      FS = ",";
      OFS = ",";
  }

  FNR == 1 {
      fileno++;
      if (fileno == 2) {
          print $0 OFS "\"RHHINCOME1999\"";
      }
      next;
  }

  fileno == 1 {
      realities[$1] = $2;
  }

  fileno == 2 {
      if ($7 == "") {
          $7 = 0;                 # make later stage processing easier
      }
      print $0 OFS realities[$1]*$7;
  }
#+END_SRC

#+BEGIN_SRC sh :shebang "#!/usr/bin/env bash" :results none
./realize <(zcat ipums/cps_00004.csv.gz) <(zcat ipums/cps_00002.csv.gz)
#+END_SRC

i'll probably have to recode all this as an R script.  how to read a
gzipped file?  [[http://grokbase.com/t/r/r-help/016v155pth/r-read-data-in-from-gzipped-file][one set of thoughts]].
: x <- gzfile("./ipums/cps_00006.csv.gz", open="r")
: y <- read.csv(x, header=TRUE)
does the right thing.

getting a file from IPUMS, extract request like this:
#+BEGIN_QUOTE

EXTRACT REQUEST (HELP)

SAMPLES:56 (show) [samples have notes] Change
VARIABLES:12(show) Change
DATA FORMAT: .csv  Change
STRUCTURE: Rectangular (person)  Change
ESTIMATED SIZE:642.4 MB 
 
OPTIONS


Data quality flags are not available for any of the variables you've
selected.

Case selection is not available for any of the variables you've
selected.

Attach data from mother, father, spouse or household head as a new
variable (for example, education of mother).  Describe your extract
#+end_quote

** deflating

need to change from nominal to real dollars.  [[https://www.dallasfed.org/research/basics/nominal.cfm][Dallas Fed]] has some
explanation.

[[https://cps.ipums.org/cps/cpi99.shtml][IPUMS]] has a variable, [[https://cps.ipums.org/cps-action/variables/CPI99][CPI99]], that can be used to convert everything
to/from 1999 dollars.

** citing IPUMS

#+BEGIN_QUOTE
Publications and research reports based on the IPUMS-CPS database must
cite it appropriately. The citation should include the following:

Sarah Flood, Miriam King, Steven Ruggles, and J. Robert
Warren. Integrated Public Use Microdata Series, Current Population
Survey: Version 5.0 [dataset]. Minneapolis, MN: University of
Minnesota, 2017.  https://doi.org/10.18128/D030.V5.0

For policy briefs or articles in the popular press that use the
IPUMS-CPS database, we recommend that you cite the use of IPUMS-CPS
data as follows:

IPUMS-CPS, University of Minnesota, www.ipums.org
#+END_QUOTE

** everylittlebit

real file is: ./ipums/cps_00006.csv.gz
#+name: everylittlebit
#+BEGIN_SRC R :session ss :var fname="./ipums/19712014.csv.gz"
  docums <- function (s) {
    cumwtsupp = sum(dset[s,]$WTSUPP)
    dset[s,]$CUMWTSUPP <<- cumsum(dset[s,]$WTSUPP)
    dset[s,]$CUMPCTWTSUPP <<- dset[s,]$CUMWTSUPP/cumwtsupp
    cumhwtsupp = sum(dset[s,]$HWTSUPP)
    dset[s,]$CUMHWTSUPP <<- cumsum(dset[s,]$HWTSUPP)
    dset[s,]$CUMPCTHWTSUPP <<- dset[s,]$CUMHWTSUPP/cumhwtsupp
  }  

  require(ggplot2)

  TOOHIGH = 10000000

  x <- gzfile(fname, open="r")
  dset <- read.csv(x, header=TRUE)
  # years are factors in our usage
  dset$YEAR <- as.factor(dset$YEAR)
  dset <- cbind(dset, HHINCOME1999=dset$HHINCOME*dset$CPI99)
  # http://answers.popdata.org/2014-WTSUPP-appears-doubled-q2066078.aspx
  dset <- dset[HFLAG==0,]
  # sort
  dset <- dset[order(dset$YEAR, dset$HHINCOME1999),]
  # negative incomes?  describe
  nrow(dset[dset$HHINCOME1999<0,])
  summary(dset[dset$HHINCOME1999<0,"HHINCOME1999"])
  # now, get rid of negative incomes
  dset <- dset[dset$HHINCOME1999 >= 0,]
  # unrealistically (?) high incomes?  describe
  nrow(dset[dset$HHINCOME1999>TOOHIGH,])
  # (use HHINCOME, since we'd like to understand *reported* [recorded?]
  # value)
  summary(dset[dset$HHINCOME1999>TOOHIGH,c("YEAR","HHINCOME")])
  # now, get rid of all of those
  dset <- dset[dset$HHINCOME1999 <= TOOHIGH,]
  # cumulative sums of [H]WTSUPP (relies on being ordered)
  dset <- cbind(dset, CUMWTSUPP=0, CUMPCTWTSUPP=0, CUMHWTSUPP=0, CUMPCTHWTSUPP=0)
  # https://stackoverflow.com/a/32487458 on computing cumpct
  for (year in unique(dset$YEAR)) {
    s <- dset$YEAR == year & (is.na(dset$HFLAG) | dset$HFLAG==0)
    docums(s)
    s <- dset$YEAR == year & (!is.na(dset$HFLAG)) & dset$HFLAG==1
    docums(s)
  }
#+END_SRC

** bincps

what we want to do is create a file which is a "binned" version of the
full-detail file.  this includes "rolling up" the [H]WTSUPP columns by
year, dropping the SERIAL, CPSID, PERNUM, CPSIDP columns in the
process.  the HHINCOME is replaced by a (computed) HHINCOME1999: the
reported HHINCOME in 1999 dollars.  this is so bins are comparable
between years.  (additionally, the MONTH column may be NA'd, if there
is more than one month in a bin -- unlikely, given that the releases
seem to be in March of every year.)

real file is: ./ipums/cps_00006.csv.gz
test file is: ./ipums/19712014.csv.gz
#+name: bincps
#+BEGIN_SRC R :session ss :var ifile="./ipums/cps_00006.csv.gz" :var ofile="" :var ofsep="-" :var rfile="" :var fyear="-" :var lyear="+" :var min1999="-" :var max1999="+"
  ## if necessary, cons up an appropriate FNAME.  then, checks that
  ## FNAME doesn't already exist and that it is (potentially) writeable.

  ## NB: as a side effect of testing writeability, on a successful
  ## return, FNAME *will* exist (but, be empty).
  bincps <- function(ifile,              # input file
                     min1999=-Inf,       # minimum HHINCOME1999 (in USD)
                     max1999=Inf,        # maximum HHINCOME1999 (in USD)
                     ## things < min1999, > max1999 are included in separate bins
                     binsize=1000,        # size of bins
                     ofile="",            # output csv file ("" ==>
                                          # compute from ifile)
                     ofsep="-",           # separator (when ofile or rfile blank)
                     rfile="",            # output report file (see ofile)
                     fyear=-Inf,          # first year to include
                     lyear=Inf            # last year to include
                     ) {
    x <- gzfile(ifile, open="r")
    print(c("about to read.csv", date()))
    dset <- read.csv(x, header=TRUE)
    print(c("done with read.csv", date()))
    close(x)

    if (nrow(dset) == 0) {
      stop(sprintf("no data in dataset \"%s\"", ifile))
    }
    ## get rid of records outside our years of interest (fyear, lyear)
    if ((fyear != -Inf) || (lyear != Inf)) {
      dset <- dset[dset$YEAR >= fyear & dset$YEAR <= lyear,]
    }

    if (nrow(dset) == 0) {
      stop(sprintf("no data in dataset \"%s\" for years between %g and %g",
                   ifile, fyear, lyear))
    }

    ## now, check if output files are okay
    orlabel <- sprintf("%d%s%d%sbinned",
                       min(dset$YEAR), ofsep,
                       max(dset$YEAR), ofsep);
    ofile <- dealwithoutputfilename(ifile, ofile, "output", orlabel)
    rfile <- dealwithoutputfilename(ifile, rfile, "report",
                                    sprintf("%s%sreport", orlabel, ofsep))

                                          # now, convert all income to 1999 dollars
    dset <- cbind(dset, HHINCOME1999=dset$HHINCOME*dset$CPI99)

    ## now, get *all* the bins...
    dset <- cbind(dset, RANGE=(floor(dset$HHINCOME1999/binsize)*binsize)+binsize)

    ## this is in lieu of a macro facility in R (or in lieu of <<noweb>>
    ## working in org-mode when running code via C-c C-c).  this routine
    ## is called to enter rows into the output table (and, can access --
    ## read and write -- our variables from the calling routine)
    ahroutine <- function(filter, upto, cpi99) {
      for (asecflag in unique(yset[filter,]$ASECFLAG)) {
        if (!is.na(asecflag)) {
          sa <- filter & yset$ASECFLAG == asecflag
        } else {
              sa <- filter & is.na(yset$ASECFLAG)
        }
        for (hflag in unique(yset[sa,]$HFLAG)) {
          if (!is.na(hflag)) {
            sh <- sa & yset$HFLAG == hflag
          } else {
            sh <- sa & is.na(yset$ASECFLAG)
          }
          if (nrow(yset[sh,]) != 0) {
            ## *finally* -- do something!
            month <- unique(yset[sh,]$MONTH)
            if (length(month) > 1) {
              month <- NA
            }
            cpi99 <- unique(yset[sh,]$CPI99)
            if (length(cpi99) > 1) {
              cpi99 <- NA
            }
            bset <<- rbind(bset,
                           data.frame(YEAR=year,
                                      HWTSUPP=sum(yset[sh,]$HWTSUPP),
                                      ASECFLAG=asecflag,
                                      HFLAG=hflag,
                                      UPTOHHINCOME99=upto,
                                      CPI99=cpi99,
                                      MONTH=month,
                                      WTSUPP=sum(yset[sh,]$WTSUPP)))
          }
        }
      }
    }

    bset <- data.frame()
    rset <- data.frame()
    for (year in sort(unique(dset$YEAR))) {
      yset <- dset[dset$YEAR == year,]
      sy <- yset$YEAR == year
      print(c(year, date()))

      ## describe and enter NA incomes
      snabit <- is.na(yset$HHINCOME1999)
      comment <- "income not provided"
      sna <- sy & snabit
      if (nrow(yset[sna,]) != 0) {
        ahroutine(sna, NA)                # enter (these) row(s)
        rset <- rbind(rset, data.frame(t(c(YEAR=year,
                                           NROW=nrow(yset[sna,]),
                                           summary(yset[sna,]$HHINCOME1999),
                                           COMMENT=comment))))
        sy <- sy & !snabit                # now, kill them
      }

      ## describe and enter the negative incomes
      slowbit <- yset[sy,]$HHINCOME1999 < min1999
      comment <- sprintf("less than %02f", min1999);
      slow <- sy & slowbit
      if (nrow(yset[slow,]) != 0) {
        ahroutine(slow, -Inf)             # enter (these) row(s)
        rset <- rbind(rset, data.frame(t(c(YEAR=year,
                                           NROW=nrow(yset[slow,]),
                                           summary(yset[slow,]$HHINCOME1999),
                                           COMMENT=comment))))
        sy <- sy & !slowbit               # now, kill them
      }

      ## now, describe too high incomes (and then enter them below)
      shighbit <- yset[sy,]$HHINCOME1999 >= max1999
      comment <- sprintf("greater than or equal to %02f", max1999);
      shigh <- sy & shighbit
      if (nrow(yset[shigh,]) != 0) {
        rset <- rbind(rset, data.frame(t(c(YEAR=year,
                                           NROW=nrow(yset[shigh,]),
                                           summary(yset[shigh,]$HHINCOME1999),
                                           COMMENT=comment))))
        sy <- sy & !shighbit              # now, kill them
      }

      ## we don't describe *other* bins since they are of limited range;
      ## the "negative" and "greater than max" bins are not of an a
      ## priori known limit.

      ## now, add all the bins
      for (bin in sort(unique(yset[sy,]$RANGE))) {
        sb <- sy & yset$RANGE == bin
        ahroutine(sb, bin)
      }

      ## now, add too high
      if (nrow(yset[shigh,]) != 0) {
        ahroutine(shigh, +Inf)
      }
    }
    write.csv(bset, ofile);
    gset <<- bset
    if (nrow(rset) != 0) {
      write.csv(rset, rfile)
    }
  }

  dealwithoutputfilename <- function(ifile, fname, use, lastbits) {
    require(assertthat)

    if (fname == "") {                    # compute filename
      x <- strsplit(ifile, ".", fixed=TRUE)[[1]]
      if (x[length(x)] == "gz") {
        length(x) = length(x)-1           # get rid of .gz (we don't compress)
      }
      x[length(x)] <- sprintf("%s.%s", lastbits, x[length(x)]);
      fname <- paste(x, collapse=".")
    }

    ## test if already exists (a no-no)
    if (file.exists(fname)) {
      stop(sprintf("%s file \"%s\" exists, won't overwrite", use, fname))
    }

    ## test if writeable (better be!)
    failed <- FALSE;
    x <- tryCatch(file(fname, "w"), 
                  error=function(e) failed <<- TRUE);
    if (failed) {
      stop(sprintf("%s file \"%s\" is not writeable", use, fname))
    }
    close(x)

    return(fname)
  }



  if (fyear == "-") {
    fyear <- -Inf
  } else {
    fyear <- as.integer(fyear)
  }
  if (lyear == "+") {
    lyear <- Inf
  } else {
    lyear <- as.integer(lyear)
  }

  if (min1999 == "-") {
    min1999 <- -Inf
  } else {
    min1999 <- as.numeric(min1999)
  }
  if (max1999 == "+") {
    max1999 <- Inf
  } else {
    max1999 <- as.numeric(max1999)
  }

  print("")
  bincps(ifile=ifile, ofile=ofile, rfile=rfile, ofsep=ofsep, fyear=fyear, lyear=lyear, min1999=min1999, max1999=max1999);
#+END_SRC
#+BEGIN_SRC R :session ss :var ifile="./ipums/19712014.csv.gz" :var ofile="" :var ofsep="-" :var rfile="" :var fyear="-" :var lyear="+"

#+RESULTS: bincps

** most occurring incomes

question:
#+BEGIN_EXAMPLE
length(unique(dset$HHINCOME1999))
[1] 55297
> length(dset$HHINCOME1999)
[1] 345582
#+END_EXAMPLE
so, what are the most occurring incomes?

#+BEGIN_EXAMPLE
> x <- dset$HHINCOME
> z <- tabulate(x)
> zz <- sort.int(z, index.return=TRUE, decreasing=TRUE)
> zz$ix[1:30]
 [1]  50000  10000  12000  30000  15000  40000  20000  25000  60000  11000
[11]   9000   8000  35000   6000  45000  13000  18000   7000  14000   5000
[21]  24000  70000  55000  75000  17000  80000  36000  16000 100000  32000
> zz$ix[1:300]
  [1]  50000  10000  12000  30000  15000  40000  20000  25000  60000  11000
 [11]   9000   8000  35000   6000  45000  13000  18000   7000  14000   5000
 [21]  24000  70000  55000  75000  17000  80000  36000  16000 100000  32000
 [31]   7500  28000  65000  22000  19000  42000  23000  90000  38000  48000
 [41]  10500  27000   6500  12500  34000  21000   4000  62000  85000   3000
 [51]  26000  52000  58000   9500   8500  33000   7800  47000  37000   8400
 [61]   4800  31000 120000 110000   9600  10200  10400  11500  14500  29000
 [71]   7200  49000  10100  44000  39000  72000   5500  46000  95000  43000
 [81]  54000  57000  10800  15600  78000  13200  11200  41000  56000  63000
 [91]  53000 150000   3600   2000  51000   5200   9200 130000  10700   4500
[101]  73000  66000   9100  68000  59000   9800  88000  76000  77000 105000
[111]  11300  61000   6600   8200  64000  98000  10300  13500   6200  12300
[121]  14400  12200  69000  97000   2400  12100  74000   1500  11700  84000
[131]   9300  17500  81000  16500  94000   9700  92000  11800  71000  83000
[141] 115000  15500  67000  82000  11100  18200  86000   8700 140000  15400
[151]  12600  14700   6800  14200   8300   8800  12400   8100   1200  12700
[161]   7400  79000  96000   8600  15200   8900 125000  10600  11600  12800
[171]   1800   3500   6400   7900   8520  18500  14300  20800  89000   5600
[181] 160000  11400  91000  19200  10900   4200  17100  87000 102000  14100
[191]  99000   9400  14800  15100  13300   7600   7100  13259  13800 103000
[201] 108000   6900  15300  16100  93000 113000   5700   6300  16300   5800
[211]   6700   7700 106000   2600   5100   9659   3900   7300  17200   2500
[221]  13100  16400  19500 135000   4900  16800   1000  13900   8652  25200
[231] 112000  17400  17600 118000  13400  26500   3200  13700  14600  16600
[241]  31200  20400 128000   2700  20500      1  15659   4680   9900  33600
[251] 104000  18100  13600 107000  14900  15800  11900 109000 145000   6100
[261]  15900  21600  26800 114000   5400  12900  21400   3300   4300  22800
[271] 117000 155000   5900  18900  20600  22200 170000  18600  22500   4700
[281]  21200 101000  19400  16700   3400  18800  20100  20200   4600  14459
[291] 116000 165000   8640  16200  25500  30200  31500  34500 111000    600
> zz$x[1:30]
 [1] 1821 1553 1270 1193 1176 1163 1070 1026  913  854  827  826  825  767  761
[16]  758  746  745  717  694  668  598  595  593  576  555  540  538  523  508
#+END_EXAMPLE
